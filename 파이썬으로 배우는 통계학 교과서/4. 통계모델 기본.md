# 4. 통계모델 기본
```
- 독립변수를 무작정 많이 넣는다고 좋은 게 아님
- 도메인 지식과 분석 목적을 고려하여 모델링하고, 변수 선택 방법을 활용하여 최적의 파라미터 조합 찾아야
```
- 통계모델 vs 평균 차이 검정(고전적)
	- 통계모델은 2가지 이상의 변수 영향을 동시에 평가할 수 있어, 올바fms 효과 분석 가능
	- ex. 마트 상품의 가격과 매상 간의 관계 분석
		1. 평균 차이 검정
			- 가격이 쌀 때와 비쌀 때의 매상 평균값을 비교해서 매상에 유의미한 차이가 있는지 검정
			- 검정 결과 가격이 쌀 때와 비쌀 때 매상 평균값에 유의미한 차이가 있음
			→ if, 세일을 하는 날(가격이 쌀 때) 대부분 비가 왔다면? 가격만의 영향으로 차이가 나타난다고 보기 어려움
		2. 통계모델
			- 날씨, 가격 등의 2가지 이상의 영향을 고려해, 세일(가격)의 효과를 더 잘 분석할 수 있음
- 독립변수와 종속변수
	- 종속변수: 독립변수에 의해 영향을 받는 변수 
	- 독립변수: 종속변수에 영향을 주는 변수
- 선형모델
	- 종속변수와 독립변수의 관계를 선형으로 보는 모델

## 4-1. parameter 추정
1. 최대우도법
- 우도나 로그우도의 결과를 최대로 하기 위한 파라미터를 추정할 때 사용하는 방법
- 여러 파라미터 조합 중 우도를 최대화하는 값을 최적의 파라미터로 고름
	- 우도
		- 파라미터가 정해져있을 때 표본을 얻을 수 잇는 확률(밀도)

2. 손실 최소화
- 손실함수
	- 파라미터 추정 시 손실을 최소화하는 목적으로 사용
	- 손실을 어떻게 정의하느냐에 따라 달라짐
	- 데이터에 따라서 손실함수를 바꿔서 사용해야함!
		- ex. 이진 분류 문제에 최소제곱법을 사용하면 제대로된 평가 못함 
- 최소제곱법(OLS)
	- 잔차제곱합(RSS)을 최소로 하는 파라미터 추정 방법이며, 효율적인 계산법이라 알려져 있음
	- 잔차제곱의 합을 사용하는 이유
		- 잔차: 실제 종속변수의 값과 종속변수 추정치의 차이
		- 잔차의 합을 사용할 경우 예측에 대한 평가가 제대로 이루어지지 않는 경우 발생      
		<img src="./image/residuals.png">

## 4-2. 예측 정확도 평가와 변수 선택
- 적합도와 예측 정확도
	- 적합도: 보유한 데이터에 모델을 적용했을 때 들어맞는 정도
	- 예측 정확도: 아직 얻지 못한 데이터에 모델을 적용했을 때 들어맞는 정도
- 과적합(overfitting)
	- 적합도는 높은데, 예측 정확도가 낮은 경우
	- 보유한 데이터에 지나치게 적합된 모델에서 발생
- 훈련/테스트 데이터
	- 훈련 데이터: 파라미터 추정에 사용되는 데이터
	- 테스트 데이터: 일반화 오차를 평가하기 위해, 파라미터 추정 시 사용하지 않고 남겨둔 데이터
- 교차검증(Cross Validation, cv)
	- 데이터를 일정한 규칙에 따라 훈련 데이터와 테스트 데이터로 나누어, 테스트 데이터에 대한 예측 정확도를 평가하는 방법
	1. Leave-p-out 교차 검증
		- p개의 데이터를 추출하고, 남은 데이터를 테스트 데이터로 사용하는 방법
		- p개의 데이터를 추출하는 방법에는 여러 조합이 잇음
		- 예측 정확도의 평균값을 평가값으로 사용
	2. K-Fold 교차검증
		- k개의 그룹으로 데이터를 나눈 후, 그 중 하나를 추출하여 테스트 데이터로 사용하는 것을 K번 반복
		- 예측 정확도의 평균값을 평가값으로 사용
	- 교차검증을 통해 예측 정확도가 최대가 되는 변수의 조합을 선택할 수 있으나, 계산량이 많아지는 단점이 있음 
 
- 아카이케 정보 기준(AIC)
	- 모델의 좋음 정도를 평가하는 지표
		- AIC가 작을수록 좋은 모델이라고 판단할 수 있음
	- AIC가 최소가 되는 변수의 조합을 선택하여, 변수 선택 가능
	- 교차검증에 비해 계산량이 적음

