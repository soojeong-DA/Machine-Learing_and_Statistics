# 7. 통계학과 머신러닝
```
- 만능 모델이라는 것은 없으므로
- 각 모델의 기본이 되는 이론을 익혀서 그때의 데이터와 목적에 맞는 모델을 사용해야 함
```

## 7-1. 머신러닝
- 컴퓨터에 학습능력을 부여하는 것을 목적으로 한 연구 분야
- 학습은 데이터를 기반으로 행해져 데이터가 가지는 규칙성을 분명히 함
	- 규칭성을 분명히 함으로써 모르는 데이터의 예측 등에 활용
- 학습 종류
	1. 지도학습
		- 정답 데이터를 얻을 수 있는 문제를 다루는 학습
		- 예측 결과가 맞는지 문제가 있는지 평가 가능
		- 정규선형모델이나 일반선형모델을 다룬 문제도 지도학습에 속한다고 볼 수 있음
	2. 비지도학습
		- 정답 데이터를 얻을 수 없는 문제를 다루는 학습
		- 정답을 얻지 못해도 가장 좋다고 생각되는 분류를 제안함
	3. 강화학습
		- 주어진 상황에서 이득이 최대가 되는 행동을 찾는 문제
		- 지도학습과는 달리 정답 데이터는 주어지지 않음
	4. 룰베이스 머신러닝
		- 사람이 미리 룰을 지정하고, 그 룰에 따라서 예측 결과 출력
		- 단순한 룰로 끝나는 문제라면, 머신러닝보다 저비용으로 효과를 볼 수도 있음
		- 복잡한 현상에 대해 적용할 경우 비효율적이며, 유연한 예측이 나오기 힘듬
- 모델 평가시 통계학에서 쓰이는 AIC 등의 기준을 사용할 수 없는 경우가 많아, 교차검증법 등이 자주 사용됨

## 7-2. 리지회귀와 라소회귀
1. 리지회귀
	- 정규화항으로 **계수의 제곱합(L2 정규화)**을 이용한 회귀모델
	- 전체적으로 절대치가 작은 회귀계수를 얻을 수 있음
		- 독립변수의 영향이 비교적 줄어들어 과적합을 방지할 수 있음
	- α를 통해 정규화의 강도 지정
		- α가 크면 영향이 강해지져, 계수의 절대값은 작아짐
	- 사전에 데이터 표준화 필요
	
2. 라소회귀
	- 정규화항으로 **계수의 절대값의 합 (L1 정규화)**을 이용한 회귀모델
	- 소수의 계수만 0이 아닌 값이 되고, 그 외에는 모두 0이되는 결과가 되기 쉬움
		- 모델에서 중요한 독립변수만 0이 아닌 값을 가지는 경우가 많아, 변수 선택으로도 쓰임
	- 샘플 사이즈보다 독립변수의 종류가 많은 데이터에도 사용할 수 있음
	- α를 통해 정규화의 강도 지정
	- 사전에 데이터 표준화 필요
	
- 정규화
	- 파라미터를 추정할 때 손실함수에 정규화항(벌칙항)을 도입함으로써 계수가 큰 값이 되는 것을 막는 기법
- 정규화 강도 α 결정
	- α를 여러 가지 수치로 변화시킨 후 **교차검증**을 이용해, 테스트 데이터에 대한 예측 정확도 평가
	- 그 중 테스트 데이터를 가장 잘 예측한 α 선택
- 표준화
	- 독립변수를 평균 0, 표준편차 1로 표준화한 것
		- 훈련 데이터와 테스트 데이터에 똑같은 변환을 적용하는 것이 중요
	- 단위가 파라미터 추정 시 영향을 주는 것을 막기 위해 모델링 전 시행

## 7-3. 신경망
- 단순 퍼셉트론
	- 입력 벡터에 가중치가 반영된 값을 합해서 하나의 출력으로 나오는 것
	- 출력과 목표 벡터(종속변수)를 비교하여 손실이 최소가 되도록 가중치를 추정
	- 출력은 -1 또는 1처럼 정해진 2개의 값 중 하나가 되는 게 보통
- 활성화함수
	- 입력 벡터에 가중치를 적용한 값을 출력으로 변환해주는 함수
	1. 스텝함수
		- 단순 퍼셉트론의 활성화함수로 쓰임
		- 반환값 
			- x<=0 → - 1
			- x >0 → 1
	2. ReLU 함수
		- 활성화함수로 많이 쓰임
		- 반환값
			- x<=0 → 0
			- x >0 → x
- 은닉층
	- 입력층과 출력층 사이에 있는 층
	- 은닉층으 포함함으로써 복잡한 관계를 알아낼 수 있음
- 신경망
	- 신경망은 사용하는 파라미터가 많지만, 그만큼 복잡한 현상을 학습시키는 데 좋음
		- 과적합될 위험성도 있음
	- 사전에 독립변수 표준화 과정 필요
	- 종류
		1. 여러층의 퍼셉트론으로 구성된 모델 (다층 퍼셉트론)
		2. 은닉층으 늘린 것을 심층학습 또는 딥러닝이라고 부름
			- 딥러닝의 경우 가중치의 결정 방법, 중간층의 개수, 중간층의 종류, 손실함수의 종류, 활성함수의 선택, L2정규화의 강도 등 많은 요소(하이퍼파라미터)를 바꿔봐야함
		3. 단순히 퍼셉트론을 늘리는 것뿐만 아니라 풀링층 같은 특별한 층을 포함할 수도 있음 (ex. 합성곱 신경망 CNN)
		


