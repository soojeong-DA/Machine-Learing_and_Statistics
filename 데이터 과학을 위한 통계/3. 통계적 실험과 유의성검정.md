# 3. 통계적 실험과 유의성 검정
```
실험설계
- 어떤 가설을 확인하거나 기각하기 위한 목표를 갖고 있음
- 통계적 추론 과정
	- 가설 수립 → 실험 설계 → 데이터 수집 → 추론 및 결론 도출

유의성검정
- 관심 있는 효과를 측정하기 위한 검정통계량을 지정하고, 
  관찰된 효과가 정상적인 랜덤 변이의 범위 내에 있는지 여부를 판단하는데 도움을 줌
- 재표본추출
	- 데이터가 수치형인지 이진형인지, 표본크기가 균형 잡혀 있는지, 표본 분산이 얼마나 큰지 등 
	  다양한 요인에 대해 걱정하지 않고, 관측된 데이터와 검증할 가설만을 신경쓰면 됨
```

## 3.1 A/B test
- 두 가지 처리 방법 중 어느 쪽이 다른 쪽보다 더 우월하다는 것을 입증하기 위해, 실험군을 두 그룹으로 나누어 진행하는 실험
- 그룹 A, B를 비교하는 데 사용하는 **검정통계량/측정 지표**는 실험 전에 미리 결정해야함  (연구자 편향 방지)
	- 대조군
		- 기존 방법 or 아무 처리도 하지 않은 대상들의 집단
		- 관심 처리를 뺀 나머지는 **처리군과 동일한 조건**이 적용돼야함
	- 처리군
		- 특정 처리에 노출된 대상들의 집단
	- 대상(피실험자)
		- 처리를 적용할 개체 대상
		- 이상적으로, 대상들은 그룹에 무작위로 배정됨

> 데이터 과학에서는?
- "A, B 차이가 통계적으로 유의한가?" 보다는 "가능한 여러 처리 중에서 가장 좋은 것은 무엇인가?"에 더 관심있음

## 3.2 가설검정
`- 관찰된 효과가 "우연"에 의한 것인지 여부 검증`
- 귀무가설과 대립가설이 모든 가능성을 설명할 수 있어야함
- 보통 귀무가설이 틀렸다는 것을 입증해서, 차이가 우연이 아니라는 것을 검증
	- 귀무가설
		- 어떤 효과가 특별한 것이 아니고, 우연에 의해 발생한 결과다
	- 대립가설
		- 귀무가설과 대조되는 가설 (증명하고자 하는 가설)
 
- 적절하게 설계된 A/B test에서는 A, B 사이의 관찰된 차이가 다음 두 가지 원인으로 설명될 수 있어야함
	1. 우연한 대상 선정
	2. A와 B의 진정한 차이
- 대리변수
	- 참된 관심 변수를 대신하는 변수
	- 관심 변수를 직접 얻을 수 없거나 측정하는 데 많은 비용, 시간이 소요되는 경우 대체하여 사용
	```
	ex. 웹디자인 A/B test. 판매되는 서비스가 고가여서 판매가 자주 발생하지 않고, 주기가 상당히 긴 경우
		- 실제 매출 데이터를 충분히 얻는 데 시간이 너무 오래 걸려, 디자인 우수성을 검증하기 어려움
		- 내부페이지 이용을 대리변수로 사용
			- 상세 랜딩 페이지 클릭 수 or 
			- 페이지에 머문 시간 측정 (세션 시간)
	```

## 3.3 재표본추출 💯
`- 랜덤한 변동성을 알아보기 위한 목표를 가지고, 관측 데이터로부터 표본을 반복적으로 추출하는 것`
- 부트스트랩
	- 추정의 신뢰성을 평가하는 데 사용됨
- 순열검정
	- 두 개 이상의 그룹과 관련된 가설을 검증하는 데 사용됨
	- 두 개 이상의 표본을 함께 결합하여 관측값들을 무작위로 재표본 추출하는 과정
		- 재표본 추출해서 관심 있는 표본통계량을 계산하는 과정을 반복하여, 순열분포 생성 
	- '실험을 통해 관찰한 차이 vs 순열 과정에서 얻은 집합에서의 차이' **비교**
		1. 관찰된 차이가 **순열분포 내**에 들어있는 경우
			- 관찰된 차이가 우연히 일어날 수 있는 범위 안에 있음 → 차이가 통계적으로 유의하지 않다
		2. 관찰된 차이가 대부분의 **순열분포 바깥**에 있는 경우
			- 차이가 우연 때문이 아니다 → 차이가 통계적으로 유의미하다


## 3.4 통계적 유의성과 p-value
- 통계적 유의성
	- 실험 결과가 우연히 일어난 것인지, 우연히 일어날 수 없는 극단적인 것인지 판단하는 방법
	- 실험 결과가 **우연히 발생할 수 있는 변동성(무작위 변이)의 바깥**에 존재한다면, 통계적으로 유의하다고 판단
	- 표본 크기가 커질수록 p-value가 더 작아짐
- p-value
	- 귀무가설로부터 나올 수 있는 결과가, 관측된 결과 같이 **특이하거나 극단적으로 나타날 확률**
- 제1종 오류
	- 우연에 의한 효과를 실제 효과(통계적으로 유의하다)라고 잘못 결론 내리는 것
	- 가설검정의 기본은 우연히 일어난 일에 속지 않는 것이므로, 1종 오류를 최소화하는 가설을 설계하는 것이 중요!
- 제2종 오류
	- 실제 효과를 우연에 의한 효과라고 잘못 결론 내리는 것
	- 오류라기보다는 표본크기가 너무 작아서 효과를 알아낼 수 없다고 판단하는 것과 같음

→ p-value 만으로 중요한 의사결정을 내리면 안됨, 통계적으로 유의하다고해서 실제적으로 유의미하다는 뜻이 아님! (정보의 일부일 뿐임)
> 데이터 과학에서 p-value는 '모델의 결과가 일반적인 랜덤 변이 범위 내에 있는지'를 알고 싶을 때 유용한 측정 지표


## 3.5 t 검정
- 과거 재표본검정을 위한 기술이 미비했을 때 자주 사용하던 검정
- 데이터가 수치형인 일반적인 2표본 비표(A/B 검정)에 주로 사용함
- 척도에 상관없이 t분포를 사용하려면, 평균과 같이 표준화된 형태의 일반적인 검정통계량(t 통계량)을 사용해야 함

## 3.6 다중검정
- 다중성(다중비교, 많은 변수, 많은 모델 등)은 일부가 우연히 유의미하다는 결론을 내릴 위험을 증가시킴
	- 다중검정 문제는 반복적으로 데이터를 샅샅이 훑는 현상과 관련있음
	- 적어도 하나의 경우에서 통계적으로 유의미한 결과를 (실수로) 초래할 가능성 높음
- 알파 인플레이션
	- 1종 오류를 만들 확률인 alpha가 더 많은 테스트를 수행할수록 증가하는 다중검정 현상
	- 오버피팅(잡음까지 피팅) 문제와 관련이 있음
		- 변수가 많을수록, 더 많은 모델을 사용할수록 우연에 의해 '유의미한' 것으로 나타날 확률이 커짐
- p-value 조정
	- 동일한 데이터에 대해 다중검정을 수행하는 경우 필요

> 데이터 과학에서의 문제 해결

1. 예측 모델링의 경우 교차타당성검사와 홀드아웃 표본을 사용
	- 실제 우연히 발생한 것을 겉보기에 유효한 것처럼 보이는 잘못된 모델을 만들 위험을 낮춰줌
2. 미리 분류된 홀드아웃 표본이 없는 다른 절차의 경우
	- 재표본추출과 시뮬레이션 결과들을 사용해 무작위 모델의 기준값을 만들어 관찰된 결과와 비교
	- 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있다는 것을 고려

## 3.7 자유도
- 표본 데이터에서 계산된 통계량에 적용되며, 변화가 가능한 값들의 개수를 나타냄
	- 모집단의 분산을 추정할 때 분모의 n-1을 사용하면 추정값의 편향이 발생하지 않음

> 데이터 과학에서는?
1. 유의성검정 측면에서는 중요하지 않음
	- 공식적인 통계 검정은 데이터 과학 분야에서 드물게 사용됨
	- 데이터 크기가 대부분 충분히 크기 때문에, 분모가 n인지 n-1인지 거의 차이가 없음
2. 회귀에서 요인변수를 사용할 때는 중요
	- 범주형 변수를 더미로 변요인화(factoring)할 때, 다중공선성 방지

## 3.8 분산분석(ANOVA)
- 여러 그룹 간의 통계적으로 유의미한 차이를 검정하는 통계적 절차
	- 그룹간 전체적인 편차가 우연히 발생할 수 있는 범위 내에 있는지
	- 재표본추출이나 F 통계량을 기반으로한 검정이 있음
- 일원/이원 분산분석
	1. 일원 ANOVA
		- A/B/C/D 검정 같이 변하는 요소(그룹)이 하나인 검정
	2. 이원 ANOVA
		- A/B/C/D + 주말/평일의 두번째 요소를 고려한 각 조합 (A-주말, A-평일, ...)에 관한 검정
		- 상호작용 효과를 확인하는 방식
		- 여러 요인과 그 효과를 모델링하는 회귀와 로지스틱 회귀 같은 통계 모델의 첫걸음이라고 할 수 있음

## 3.9 카이제곱검정
- 횟수 관련 데이터에 주로 사용되며, 예상되는 분포(기대분포)에 얼마나 잘 맞는지 검정
	- 일반적으로 변수간 독립성(결과가 변수와 무관함)에 대한 귀무가설이 타당한지 평가하기 위해 r x c 분할표와 함께 사용
	- 귀무가설에서는 모두가 동일한 발생 확률을 갖는다는 가정 ex. 테스트 페이지별 동일한 클릭률을 갖는다
- 관찰된 결과가 귀무가설(랜덤)로부터 얻을 수 있는 결과인지 (우연히 발생한 차이인지) 검정
- 피셔의 정확검정
	- 발생할 수 있는 모든 조합(순열)을 열거, 빈도 집계, 관찰된 결과가 얼마나 극단적으로 발생할 수 있는지를 정확하게 검정

→ 어떤 효과가 실제인지 or 우연인지 알고싶을 때 사용

> 데이터 과학에서는?
- 웹 실험의 적합한 표본크기를 판별하는데 활용
- 랜덤인 경우보다 특정 영역에서 발생이 집중되는지
- 머신러닝에서 자동 특성 선택을 위해 사용
```
→ 대부분의 데이터 과학 실험에서 목표는 유의성 검정이 아닌, 최적의 처리 방법을 찾는 것이므로, 
   '멀티암드 밴딧' 방법이 더 정확한 해결책으로 사용됨
```



 