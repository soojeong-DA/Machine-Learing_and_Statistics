# 5. 분류
```
- 일반적으로 관심 있는 class가 상대적으로 드물게 발생하는 경우가 많아(불균형), 목적에 맞는 분류 모델 '평가 지표' 선정이 중요
- 관심 class에 대한 컷오프(절사) 확률 조정 가능
	- 컷오프가 높을수록 1(관심 class)로 예측되는 레코드가 적어짐
	- 컷오프가 낮을수록 더 많은 레코드가 1로 예측됨
- 하나의 카테고리가 다른 카테고리보다 훨씬 더 일반적인 경우
	- 멀티 클래스 문제라도 이진 분류 문제로 변환하는 것이 유리할 수도 있음
```

## 5.1 나이브 베이즈
- 주어진 결과에 대해 예측변수값을 관찰할 확률(사전 확률)을 사용하여, 예측변수가 주어졌을 때 결과를 관찰할 확률(사후 확률)을 반환
 	- 예측변수들이 서로 독립이라고 가정하는 베이즈 정리 이용 (모든 사건이 독립사건이라는 naive한 가정)
	- 모델로부터 나온 결과가 조건부확률이 됨
		- 조건부확률
			- 어떤 사건이 주어졌을 때, 해당 사건을 관찰할 확률
		- 사후확률
			- 예측 정보를 통합한 후 결과의 확률
			- 사전확률에서는 예측변수에 대한 정보를 고려하지 않음
		- ```
		    "각 출력 카테고리 안에서, 어떤 예측변수의 카테고리가 가장 가능성이 높은가?"의 확률을 출력
		    → 이 정보는 주어진 예측변수 값에 대해 결과 카테고리의 확률을 추정하는 것으로 바뀜 (조건부확률로 활용됨)
		  ```
- 예측변수가 범주형인 경우에 적합하며, 수치형인 경우 구간화하여 범주형으로 변환해야함

## 5.2 판별분석
- 선형판별분석(LDA, Linear discriminant analysis)
	- 가장 일반적으로 사용되는 판별분석 기법
	- 트리 모델, 로지스틱 회귀 같은 더 정교한 기법 출현 이후 LDA는 많이 사용하지 않고, 일부 응용 분야에서만 사용됨
	- 예측변수가 정규분포를 따르는 연속적인 변수여야하는 이론적인 가정이 있지만, 정규분포에서 벗어나거나 이진 예측변수에도 잘 동작함
	- '사이 제곱합(다른 그룹 간의 편차 제곱) / 내부 제곱합(그룹 안의 편차)'의 비율을 최대화하는 선형결합을 찾음
		- 사이 제곱합을 최대화, 내부 제곱합을 최소화하는 것이 분류를 가장 명확히 하는 방법
	- 변수 선택에 사용 가능
		- 예측변수들을 정규화한 뒤 LDA를 돌린 결과인 '판별 가중치' = '변수의 중요도'
	- 예측결과인 확률(가중치)를 시각화해서 모델이 잘 동작하는 지 판단 가능
- 이차판별분석(QDA, Quadratic discniminant analysis)
	- 선형판별함수를 사용하지만 가정이 다름
		- LDA: Y=0, Y=1 두 그룹 간의 공분산행렬이 모두 동일해야함
		- QDA: 두 그룹이 서로 다른 공분산을 가질 수 있음

→ 실무에서 대부분의 경우 두 판별분석 기법의 차이가 크지 않음 

## 5.3 로지스틱 회귀
- 결과가 이진형 변수라는 것만 빼면 선형회귀와 유사
	- 로지스틱 회귀는 최대우도추정(MLE) 사용함
		- 응답변수는 0 or 1이 아닌, 응답이 1인 로그 오즈비의 추정치임
			- 오즈(odds): 실패(0)에 대한 성공(1)의 비율
		- 편차 지표를 사용하여 모델을 평가
	- 선형회귀에서 처럼 범주형(요인)변수 인코딩해야함 (기준인코딩, 원핫인코딩)
- 데이터 기반의 접근방식(ex. knn, naive bayes)보다는 구조화된 모델 접근 방식
- 계산 속도가 빠르며, 새로운 데이터에 대해서도 간단한 산술연산으로 빠르게 결과를 구할 수 있음 ← 많이 사용되는 이유
- 파이썬에서 로지스틱 회귀
	- L1 or L2 정규화에 의한 과적합을 방지하기 위해 penalty와 C 인수 사용 (기본으로 정규화는 적용되어 있음)
	- solver 인수는 사용할 최소화 방법 선택 (기본값 = liblinear)

> p-value
- R로 로지스틱 회귀 모델링 했을 때 p-value 해석
	- 통계적인 유의성 측정 지표로 보기 보다는 '변수의 중요성'을 나타내는 상대적인 지표로 봐야함

## 5.4 분류 모델 평가
- 컷오프 기준 확률
	- 기본값은 0.5
	- 실제 데이터에서 1이 차지하는 비율을 컷오프로 사용하는 방법도 있음
- 클래스간 불균형이 있을 때 '평가 지표' 선정 중요
	- 0을 잘못 구분해서 전반적인 정확도가 떨어지더라도, 1(관심 있는)을 잘 골라내는 모델이 더 나음
- 이상적인 분류기 
	- 0을 1이라고 잘못 분류하지 않으면서 1을 잘 분류하는 분류기

1. Accuracy(정확도)
	- 정확히 분류된 비율
2. Confusion Matrix
	- 분류 예측 결과와 실제 결과에 대한 레코드 개수 표시한 테이블
		- column은 예측값, row는 실제값을 의미함
		- 대각선의 값들은 정확히 예측한 데이터의 수, 비대각선의 원소들은 부정확한 예측의 수를 나타냄
	- 거짓양성(FP) 비율
		- 실제 데이터에 1인 데이터의 수가 희박할 때 거짓양성 비율이 높아져, 예측결과는 1이지만 실제로는 0일 가능성이 높아짐 
3. Recall(재현율) = Sensitivity(민감도) 
	- 실제 1을 정확히 1로 분류한 비율
	- 양성 결과를 예측하는 모델의 능력을 평가	
4. Specificity(특이도)
	- 실제 0을 정확히 0으로 분류한 비율
	- 음성 결과를 정확히 예측하는 능력을 측정
5. Precision(정밀도)
	- 1이라고 예측한 것들 중에 실제 1인 경우의 비율
	- 예측된 양성 결과의 정확도를 의미	
6. ROC curve
	- 컷오프 값을 바꿀 때 재현율과 특이도 사이의 trade-off 관계를 표현한 그래프
		- 대각선 점선은 랜덤으로 예측했을 떄의 결과를 의미
		- 왼쪽 상단에 가까울 수록, 0을 1로 잘못 예측하는 경우 없이 1을 정확히 예측함 
	- AUC
		- 분류기 성능을 나타내는 지표 (ROC curve 아래 면적)
			- 값이 높을수록 분류 성능이 좋음
			- 0.5일때 성능이 좋지 않음 (랜덤 분류랑 성능 똑같다는 의미...)
		- 단편적인 지표의 한계로 모델의 적합성을 여러 가지 측면에서 보기 어려울 수 있음	
7. PR curve
	- 정밀도-재현율(PR) 곡선으로 클래스 간 데이터 불균형이 심할 때 유용
8. Lift(gain)
	- 다른 확률 컷오프에 대해  (비교적 드문) 1을 얼마나 '더 효과적으로 구분하는지'의 측정 지표
	- ```
		ex. 무작위로 선택하는 경우 0.1%의 정확도 vs 상위 10% 레코드를 1로 분류하는 경우 0.3%의 정확도
			→ 상위 10%에서 3의 리프트(이득)을 갖음
	  ```
	- 리프트 곡선
		-  레코드를 1로 분류하기 위한 확률 컷오프 값에 따른 결과의 변화를 한눈에 볼 수 있게함
		- 적합한 컷오프 값을 결정하기 위한 중간 단계로  활용 가능

## 5.5 불균형 데이터
- 데이터의 심각한 불균형(관심 있는 데이터가 희박할 때) 시 분류 알고리즘에서 문제가 될 수 있음
1. 다운샘플링
	- 다수 클래스를 다운샘플링해서 모델링 시 0과 1의 데이터 개수에 균형을 맞추는 것
	- 모든 정보를 활용하지 못하며, 유용한 데이터의 일부까지 소실될 수 있는 위험이 있음 
2. 업 샘플링
	- 희귀 클래스 데이터를 복원추출 방식(부트스트랩)으로 업샘플링해서 사용
3. 상향/하향 가중치
	- 희귀/다수 클래스에 높은/낮은 가중치를 줌으로써 업/다운 샘플링과 비슷한 효과를 얻을 수 있음 (대체 가능)
	- 손실함수를 변경하는 쉬운 방법임
		- 가중치가 높은 데이터를 선호하고, 가중치가 낮은 데이터의 오류를 줄여주는 식 
4. 데이터 생성
	- 비슷하지만 기존의 데이터와 다른 데이터를 생성해서, 좀 더 robust한 분류 규칙을 학습할 수 있는 기회를 주는 것
	- SMOTE 알고리즘으로 새로운 합성 데이터 생성

> 비용이 평가 지표에 반영되어야
-  AUC, Accuracy 등의 지표만으로 판단 내리는 것이 아닌, 실제적으로 예상되는 기대수익(비용, 수익)을 종합적으로 고려해 최상의 cut-off 결정
