# 5. 분류
```
- 이진분류(0 or 1), 세가지 이상의 class 중 어디에 속할지 예측
	- 대부분의 알고리즘은 관심 클래스에 속할 확률을 반환함
	- 관심 class에 대한 컷오프(절사) 확률을 정하여 조정 가능
		- 컷오프가 높을수록 1(관심 class)로 예측되는 레코드가 적어짐
		- 컷오프가 낮을수록 더 많은 레코드가 1로 예측됨
- 하나의 카테고리가 다른 카테고리보다 훨씬 더 일반적인 경우
	- 멀티 클래스 문제라도 이진 분류 문제로 변환하는 것이 유리할 수도 있음
```

## 5.1 나이브 베이즈
- 주어진 결과에 대해 예측변수값을 관찰할 확률(사전 확률)을 사용하여, 예측변수가 주어졌을 때 결과를 관찰할 확률(사후 확률)을 반환
 	- 예측변수들이 서로 독립이라고 가정하는 베이즈 정리 이용 (모든 사건이 독립사건이라는 naive한 가정)
	- 모델로부터 나온 결과가 조건부확률이 됨
		- 조건부확률
			- 어떤 사건이 주어졌을 때, 해당 사건을 관찰할 확률
		- 사후확률
			- 예측 정보를 통합한 후 결과의 확률
			- 사전확률에서는 예측변수에 대한 정보를 고려하지 않음
		- ```
		    "각 출력 카테고리 안에서, 어떤 예측변수의 카테고리가 가장 가능성이 높은가?"의 확률을 출력
		    → 이 정보는 주어진 예측변수 값에 대해 결과 카테고리의 확률을 추정하는 것으로 바뀜 (조건부확률로 활용됨)
		  ```
- 예측변수가 범주형인 경우에 적합하며, 수치형인 경우 구간화하여 범주형으로 변환해야함

## 5.2 판별분석
- 선형판별분석(LDA, Linear discriminant analysis)
	- 가장 일반적으로 사용되는 판별분석 기법
	- 트리 모델, 로지스틱 회귀 같은 더 정교한 기법 출현 이후 LDA는 많이 사용하지 않고, 일부 응용 분야에서만 사용됨
	- 예측변수가 정규분포를 따르는 연속적인 변수여야하는 이론적인 가정이 있지만, 정규분포에서 벗어나거나 이진 예측변수에도 잘 동작함
	- '사이 제곱합(다른 그룹 간의 편차 제곱) / 내부 제곱합(그룹 안의 편차)'의 비율을 최대화하는 선형결합을 찾음
		- 사이 제곱합을 최대화, 내부 제곱합을 최소화하는 것이 분류를 가장 명확히 하는 방법
	- 변수 선택에 사용 가능
		- 예측변수들을 정규화한 뒤 LDA를 돌린 결과인 '판별 가중치' = '변수의 중요도'
	- 예측결과인 확률(가중치)를 시각화해서 모델이 잘 동작하는 지 판단 가능
- 이차판별분석(QDA, Quadratic discniminant analysis)
	- 선형판별함수를 사용하지만 가정이 다름
		- LDA: Y=0, Y=1 두 그룹 간의 공분산행렬이 모두 동일해야함
		- QDA: 두 그룹이 서로 다른 공분산을 가질 수 있음

→ 실무에서 대부분의 경우 두 판별분석 기법의 차이가 크지 않음 

## 5.3 로지스틱 회귀
- 결과가 이진형 변수라는 것만 빼면 선형회귀와 유사
	- 로지스틱 회귀는 최대우도추정(MLE) 사용함
		- 응답변수는 0 or 1이 아닌, 응답이 1인 로그 오즈비의 추정치임
			- 오즈(odds): 실패(0)에 대한 성공(1)의 비율
		- 편차 지표를 사용하여 모델을 평가
	- 선형회귀에서 처럼 범주형(요인)변수 인코딩해야함 (기준인코딩, 원핫인코딩)
- 데이터 기반의 접근방식(ex. knn, naive bayes)보다는 구조화된 모델 접근 방식
- 계산 속도가 빠르며, 새로운 데이터에 대해서도 간단한 산술연산으로 빠르게 결과를 구할 수 있음 ← 많이 사용되는 이유
- 파이썬에서 로지스틱 회귀
	- L1 or L2 정규화에 의한 과적합을 방지하기 위해 penalty와 C 인수 사용 (기본으로 정규화는 적용되어 있음)
	- solver 인수는 사용할 최소화 방법 선택 (기본값 = liblinear)

> p-value
- R로 로지스틱 회귀 모델링 했을 때 p-value 해석
	- 통계적인 유의성 측정 지표로 보기 보다는 '변수의 중요성'을 나타내는 상대적인 지표로 봐야함

## 5.4 분류 모델 평가
- 컷오프 기준 확률
	- 기본값은 0.5
	- 실제 데이터에서 1이 차지하는 비율을 컷오프로 사용하는 방법도 있음
- 클래스간 불균형이 있을 때 평가 지표 잘 선정해야함
	- 0을 잘못 구분해서 전반적인 정확도가 떨어지더라도, 1을 잘 골라내는 모델이 더 나음

1. Accuracy(정확도)
	- 정확히 분류된 비율
2. Confusion Matrix
	- 분류 예측 결과와 실제 결과에 대한 레코드 개수 표시한 테이블
		- column은 예측값, row는 실제값을 의미함
		- 대각선의 값들은 정확히 예측한 데이터의 수, 비대각선의 원소들은 부정확한 예측의 수를 나타냄
	- 거짓양성(FP) 비율
		- 실제 데이터에 1인 데이터의 수가 희박할 때 거짓양성 비율이 높아져, 예측결과는 1이지만 실제로는 0일 가능성이 높아짐 
3. Recall(재현율) = Sensitivity(민감도) 
	- 실제 1을 정확히 1로 분류한 비율
	- 양성 결과를 예측하는 모델의 능력을 평가	
4. Specificity(특이도)
	- 실제 0을 정확히 0으로 분류한 비율
	- 음성 결과를 정확히 예측하는 능력을 측정
5. Precision(정밀도)
	- 1이라고 예측한 것들 중에 실제 1인 경우의 비율
	- 예측된 양성 결과의 정확도를 의미	
6. ROC curve
	- 민감도와 특이도를 표시한 그래프
7. Lift
	- 다른 확률 컷오프에 대해  (비교적 드문) 1을 얼마나 더 효과적으로 구분하는지의 측정 지표